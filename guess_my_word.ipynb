{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"guess_my_word.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guess My Word\n",
    "\n",
    "#### Authors:\n",
    "v1.0 (Spring 2020) William Gan, Kannan Ramchandran\n",
    "v1.1 (Fall 2024) Tianhao Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In Guess My Word http://hryanjones.com/guess-my-word/, you make guesses at a secret word and the computer tells you if it's before or after. Being bad at it, Efe wants to write a program to solve it. In this lab, you'll explore a couple ideas he has and help him write the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Game\n",
    "\n",
    "Suppose we have obtained a list of the words used in the game. Each word has a frequency representing relatively how often it appears in the English language. Suppose the secret word is chosen proportionally to this frequency. The code in the cells below simulate the game. A couple things to note:\n",
    "\n",
    "- The frequency is not a probability i.e. it is unnormalized.\n",
    "- In this version of the game, we're assuming guesses come from the list of possible words used.\n",
    "- We're also assuming that you aren't told the secret word if you guess it. You have to deduce it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_FREQ = {'course': 78, 'against': 221, 'ready': 115, 'daughter': 64, 'work': 106, 'friends': 32, 'minute': 21, 'though': 339, 'supposed': 21, 'honey': 6, 'point': 64, 'start': 20, 'check': 9, 'alone': 154, 'matter': 104, 'office': 8, 'hospital': 18, 'three': 220, 'already': 298, 'anyway': 2, 'important': 110, 'tomorrow': 34, 'almost': 146, 'later': 94, 'found': 212, 'trouble': 23, 'excuse': 21, 'money': 79, 'different': 115, 'between': 233, 'every': 293, 'party': 45, 'either': 94, 'enough': 33, 'year': 53, 'house': 231, 'story': 49, 'crazy': 1, 'mind': 125, 'break': 27, 'tonight': 5, 'person': 54, 'sister': 30, 'pretty': 44, 'trust': 7, 'funny': 10, 'gift': 4, 'change': 69, 'business': 57, 'train': 21, 'under': 360, 'close': 98, 'reason': 87, 'today': 24, 'beautiful': 65, 'brother': 69, 'since': 159, 'bank': 13, 'yourself': 58, 'without': 633, 'until': 18, 'forget': 62, 'anyone': 112, 'promise': 22, 'happy': 141, 'worry': 3, 'school': 1, 'afraid': 116, 'cause': 111, 'doctor': 80, 'exactly': 23, 'second': 99, 'look': 359, 'feel': 121, 'somebody': 8, 'stuff': 1, 'morning': 121, 'heard': 411, 'world': 84, 'chance': 41, 'call': 74, 'watch': 19, 'whatever': 41, 'perfect': 16, 'dinner': 89, 'family': 80, 'heart': 101, 'least': 77, 'answer': 97, 'woman': 95, 'bring': 71, 'probably': 67, 'question': 144, 'stand': 40, 'truth': 32, 'problem': 13, 'patch': 3, 'pass': 54, 'famous': 19, 'true': 63, 'power': 124, 'cool': 2, 'last': 316, 'fish': 4, 'remote': 12, 'race': 7, 'noon': 4, 'wipe': 3, 'grow': 26, 'learn': 15, 'itself': 117, 'chip': 4, 'print': 2, 'young': 397, 'argue': 3, 'clean': 24, 'remove': 6, 'flew': 43, 'replace': 5, 'side': 218, 'walk': 28, 'gate': 28, 'finger': 20, 'target': 1, 'judge': 25, 'push': 11, 'thought': 608, 'wear': 10, 'desert': 1, 'relief': 14, 'bright': 54, 'deal': 22, 'father': 182, 'machine': 9, 'know': 623, 'step': 49, 'exercise': 14, 'present': 90, 'wing': 9, 'ship': 11, 'wait': 42, 'fancy': 14, 'eight': 31, 'hall': 31, 'rise': 12, 'river': 27, 'round': 351, 'girl': 84, 'winter': 29, 'speed': 14, 'long': 452, 'oldest': 3, 'lock': 10, 'kiss': 30, 'garden': 32, 'fight': 56, 'hook': 2, 'desk': 3, 'test': 6, 'serious': 55, 'exit': 1, 'branch': 5, 'keyboard': 1, 'naked': 18, 'science': 32, 'trade': 2, 'quiet': 57, 'home': 91, 'prison': 2, 'blue': 64, 'window': 64, 'whose': 101, 'spot': 39, 'dark': 74, 'create': 2, 'quick': 23, 'face': 609, 'terrible': 122, 'accept': 24, 'door': 186, 'touch': 29, 'care': 37, 'rescue': 5, 'real': 66, 'title': 7, 'city': 39, 'fast': 18, 'season': 1, 'town': 67, 'picture': 11, 'tower': 4, 'engine': 2, 'lift': 23, 'respect': 34, 'time': 638, 'mission': 8, 'play': 41, 'discover': 9, 'half': 118, 'unusual': 13, 'ball': 66, 'tool': 3, 'heavy': 47, 'night': 124, 'farm': 2, 'firm': 35, 'gone': 133, 'help': 128, 'easy': 38, 'library': 3, 'group': 54, 'taste': 10, 'large': 149, 'imagine': 56, 'normal': 6, 'outside': 39, 'paper': 39, 'nose': 19, 'doing': 103, 'moon': 6, 'hour': 50, 'protect': 9, 'hate': 13, 'dead': 46, 'double': 15, 'nothing': 318, 'restaurant': 2, 'reach': 32, 'note': 27, 'tell': 327, 'baby': 20, 'future': 56, 'tall': 39, 'drop': 16, 'speak': 168, 'rule': 14, 'pair': 19, 'ride': 41, 'game': 30, 'hair': 94, 'hurt': 21, 'allow': 44, 'oven': 2, 'live': 71, 'horse': 154, 'bottle': 31, 'rock': 1, 'public': 28, 'find': 158, 'green': 38, 'heat': 19, 'plan': 62, 'mean': 35, 'little': 513, 'spend': 24, 'nurse': 29, 'practice': 5, 'wish': 165, 'uncle': 2, 'core': 1, 'stop': 40, 'number': 66, 'nest': 2, 'pool': 5, 'message': 12, 'active': 23, 'throw': 25, 'pull': 10, 'level': 11, 'wrist': 1, 'hold': 59, 'huge': 36, 'finish': 26, 'teeth': 21, 'flag': 7, 'head': 382, 'private': 24, 'together': 72, 'child': 51, 'decide': 16, 'listen': 46, 'jealous': 12, 'wide': 24, 'straight': 92, 'fall': 63, 'joke': 16, 'table': 116, 'spread': 58, 'deep': 69, 'quit': 3, 'save': 36, 'worst': 18, 'email': 2, 'glass': 44, 'scale': 1, 'safe': 7, 'path': 48, 'excellent': 26, 'place': 229, 'zone': 1, 'luck': 13, 'sign': 43, 'report': 48, 'myself': 83, 'knee': 12, 'need': 97, 'root': 1, 'light': 96, 'sure': 60, 'page': 10, 'life': 331, 'space': 22, 'magic': 4, 'size': 6, 'food': 22, 'period': 34, 'mistake': 16, 'full': 153, 'paid': 41, 'horrible': 6, 'special': 70, 'hidden': 20, 'rain': 15, 'field': 104, 'kick': 1, 'ground': 57, 'screen': 7, 'risky': 1, 'human': 102, 'nobody': 20, 'high': 95, 'class': 15, 'street': 28, 'cold': 93, 'metal': 6, 'nervous': 12, 'wind': 22, 'summer': 22, 'president': 1, 'empty': 23, 'square': 10, 'popular': 8, 'loud': 40, 'online': 4, 'something': 479, 'knot': 7, 'mark': 8, 'road': 113, 'storm': 9, 'said': 2406, 'floor': 25, 'theater': 11, 'kitchen': 6, 'action': 122, 'equal': 24, 'nice': 24, 'dream': 15, 'sound': 144, 'fifth': 17, 'talk': 199, 'police': 20, 'draw': 24, 'bunch': 1, 'idea': 54, 'jerk': 3, 'copy': 10, 'success': 34, 'favor': 18, 'open': 84, 'neat': 1, 'gold': 28, 'free': 116, 'mile': 20, 'lying': 67, 'meat': 3, 'nine': 19, 'wonderful': 15, 'hero': 17, 'quilt': 5, 'move': 60, 'early': 43, 'remember': 79, 'understand': 255, 'month': 20, 'everyone': 160, 'quarter': 18, 'center': 36, 'universe': 3, 'name': 72, 'inside': 14, 'yell': 4, 'jacket': 10, 'nation': 16, 'support': 15, 'lunch': 7, 'twice': 39, 'boot': 11, 'alive': 16, 'build': 5, 'date': 4, 'room': 385, 'fire': 115, 'music': 27, 'leader': 8, 'rest': 70, 'plant': 5, 'connect': 1, 'land': 15, 'body': 66, 'belong': 12, 'trick': 4, 'wild': 11, 'quality': 8, 'band': 17, 'health': 29, 'love': 345, 'hand': 314, 'yeah': 1, 'dozen': 16, 'glove': 7, 'give': 249, 'thick': 26, 'flow': 12, 'project': 9, 'tight': 11, 'join': 42, 'cost': 24, 'trip': 2, 'lower': 34, 'angry': 86, 'line': 74, 'rich': 34, 'owner': 8, 'block': 5, 'shut': 19, 'neck': 37, 'write': 45, 'hotel': 2, 'danger': 40, 'impossible': 113, 'illegal': 2, 'show': 100, 'come': 493, 'want': 211, 'click': 5, 'none': 34, 'done': 224, 'hope': 65, 'share': 25, 'water': 48, 'dust': 16, 'handle': 8, 'unhappy': 12, 'guess': 7, 'past': 119, 'frame': 14, 'knob': 2, 'ugly': 3, 'lesson': 4, 'bear': 40, 'gross': 3, 'midnight': 8, 'grass': 8, 'middle': 73, 'birthday': 1, 'rose': 147, 'useless': 21, 'hole': 5, 'drive': 45, 'color': 12, 'sell': 4, 'unfair': 1, 'send': 59, 'crash': 2, 'knife': 2, 'wrong': 36, 'guest': 7, 'strong': 51, 'weather': 15, 'undo': 2, 'catch': 23, 'neighbor': 7, 'stream': 3, 'random': 4, 'continue': 16, 'return': 81, 'begin': 52, 'kitten': 6, 'thin': 65, 'pick': 8, 'whole': 522, 'useful': 12, 'rush': 16, 'mine': 11, 'toilet': 2, 'enter': 58, 'wedding': 9, 'wood': 32, 'meet': 101, 'stolen': 7, 'hungry': 14, 'card': 15, 'fair': 9, 'crowd': 152, 'glow': 16, 'ocean': 1, 'peace': 59, 'match': 17, 'hill': 45, 'welcome': 6, 'across': 111, 'drag': 5, 'island': 7, 'edge': 22, 'great': 225, 'feet': 77, 'iron': 3, 'wall': 19, 'fill': 5, 'boat': 3, 'hard': 64, 'happen': 45, 'tiny': 6, 'event': 57, 'recently': 10, 'seven': 52, 'tree': 17, 'rough': 13, 'secret': 33, 'nature': 15, 'short': 87, 'inch': 1, 'raise': 16, 'warm': 32, 'gentle': 30, 'roll': 13, 'search': 20, 'regular': 27, 'here': 206, 'count': 232, 'hunt': 15, 'keep': 75, 'week': 21, 'venerable': 4, 'exemplary': 4, 'extenuating': 1, 'mundane': 2, 'hypothesis': 1, 'scrutinize': 1, 'tenacious': 1, 'prosperity': 2, 'compromise': 3, 'submissive': 7, 'wary': 1, 'amicable': 1, 'superficial': 2, 'brusque': 1, 'reconciliation': 1, 'brazen': 1, 'benevolent': 2, 'conditional': 2, 'disdain': 4, 'asylum': 4, 'compassion': 1, 'condescending': 6, 'querulous': 4, 'inevitable': 21, 'renovation': 1, 'provocative': 2, 'subtle': 15, 'diligent': 2, 'orator': 2, 'superfluous': 6, 'tactful': 2, 'restrained': 8, 'abstain': 2, 'reverence': 1, 'spontaneous': 1, 'haughty': 1, 'parched': 1, 'impute': 1, 'transient': 2, 'confluence': 2, 'conventional': 2, 'sufficient': 14, 'negligence': 2, 'temporary': 3, 'regret': 14, 'words': 265, 'diminish': 2, 'plausible': 1, 'necessity': 42, 'diminutive': 2, 'capture': 32, 'keen': 9, 'delirious': 2, 'lunatic': 5, 'fraternity': 1, 'loathe': 1, 'entrenched': 4, 'foment': 2, 'counteract': 1, 'subsequent': 2, 'eccentric': 1, 'decree': 4, 'devise': 5, 'enumerate': 1, 'caricature': 1, 'ridiculous': 7, 'dispatch': 11, 'sacrilegious': 1, 'saucer': 1, 'undermine': 1, 'superb': 1, 'exhilarating': 1, 'suspicious': 2, 'garment': 2, 'typical': 1, 'coarse': 12, 'repudiate': 1, 'frock': 2, 'theoretical': 1, 'contemplate': 5, 'anticipate': 2, 'confide': 3, 'constitution': 2, 'ferocious': 2, 'justify': 12, 'reinforce': 1, 'virtuous': 10, 'dilemma': 1, 'provincial': 5, 'establish': 3, 'renounce': 8, 'invade': 1, 'coincide': 2, 'deference': 3, 'scorn': 2, 'dignity': 19, 'complacent': 3, 'sheath': 1, 'austere': 2, 'nuisance': 4, 'jarring': 1, 'amiable': 12, 'condemn': 6, 'indifferent': 17, 'stupendous': 1, 'theology': 2, 'confound': 2, 'retention': 1, 'provision': 3, 'knight': 2, 'callous': 1, 'refute': 1, 'restoration': 3, 'momentous': 1, 'reconsider': 1, 'withstand': 5, 'virile': 1, 'calamity': 3, 'hypothetical': 1, 'demonstrate': 2, 'flourish': 2, 'peculiar': 28, 'hostile': 17, 'vicious': 10, 'malicious': 1, 'stark': 1, 'perish': 9, 'intimate': 37, 'allegory': 1, 'righteous': 1, 'reconcile': 3, 'saber': 17, 'placid': 1, 'universal': 23, 'recompense': 1, 'jaded': 1, 'astute': 1, 'concise': 1, 'surly': 1, 'recite': 3, 'quench': 1, 'valiant': 4, 'fatigue': 5, 'remnant': 2, 'query': 1, 'marauder': 2, 'chalice': 1, 'hitherto': 9, 'brute': 2, 'narrative': 2, 'supercilious': 1, 'heritage': 1, 'novice': 1, 'delusion': 3, 'grim': 4, 'quizzical': 1, 'conduct': 13, 'tension': 2, 'expend': 1, 'tremendous': 5, 'providence': 1, 'robust': 2, 'altercation': 1, 'convey': 3, 'substantial': 2, 'sumptuous': 1, 'frankly': 9, 'yield': 9, 'emphatic': 3, 'adhere': 1, 'conceive': 12, 'reform': 7, 'delicate': 27, 'contradict': 10, 'sinister': 2, 'arsenal': 2, 'vital': 7, 'brunt': 2, 'jolt': 1, 'rapture': 6, 'conviction': 20, 'deliberate': 6, 'discord': 2, 'vigor': 4, 'allude': 1, 'envy': 10, 'doctrine': 1, 'cultivate': 1, 'commission': 5, 'reluctant': 9, 'braggart': 1, 'stature': 1, 'eloquent': 2, 'fiscal': 1, 'competent': 1, 'apprehensive': 2, 'transparent': 5, 'horizontal': 1, 'gauge': 1, 'prompt': 3, 'endure': 15, 'subordinate': 6, 'lucrative': 2, 'exploit': 2, 'assertion': 1, 'innate': 2, 'exert': 2, 'election': 1, 'reproach': 21, 'notorious': 5, 'billet': 1, 'dismay': 9, 'imposing': 4, 'transaction': 1, 'bolster': 1, 'stationary': 2, 'irrational': 3, 'dreary': 1, 'novel': 6, 'quaint': 1, 'recalcitrant': 1, 'jovial': 2, 'responsibility': 18, 'pinnacle': 1, 'forage': 4, 'indulge': 2, 'annihilate': 3, 'zenith': 1, 'sentiment': 2, 'fundamental': 3, 'principle': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_freq = sum(WORD_FREQ.values())\n",
    "sorted_words = sorted(list(WORD_FREQ))\n",
    "sorted_word_freqs = np.array([WORD_FREQ[w] for w in sorted_words])\n",
    "cum_freqs = np.cumsum(sorted_word_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total frequency: {total_freq}')\n",
    "print(f'First 10 words sorted: {sorted_words[:10]}')\n",
    "print(f'Frequencies associated with these words: {sorted_word_freqs[:10]}')\n",
    "print(f'Cumulative freqs associated with these words: {cum_freqs[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will use binary search to find the word associated with an idx, which should be from 0 to total_freq-1. For example, `binary_search_word_generation(126)` will return the 3rd word, \"across\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_word_generation(idx):\n",
    "    i, j = 0, len(sorted_words) - 1\n",
    "    while i < j:\n",
    "        mid = (i + j) // 2\n",
    "        if cum_freqs[mid] > idx:\n",
    "            j = mid\n",
    "        else:\n",
    "            i = mid + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following cell, implement `generate_secret_word` using `binary_search_word_generation`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_secret_word():\n",
    "    \"\"\"Generate a random word from the word list, weighted by word frequency.\n",
    "    \n",
    "    You should approach this problem by:\n",
    "    1. Generating a random integer between 0 and total_freq-1.\n",
    "    2. Using binary_search_word_generation to find the word associated with that integer.\n",
    "    \"\"\"\n",
    "    # BEGIN SOLUTION\n",
    "    rand_idx = np.random.randint(total_freq)\n",
    "    return sorted_words[binary_search_word_generation(rand_idx)]\n",
    "    # END SOLUTION\n",
    "\n",
    "assert generate_secret_word() in WORD_FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"generate_secret_word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates a game by generating a secret word and returning `guess_function`. `guess_function` returns True if the guess is lexicographically \"less than\" the secret word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_game(secret_word):\n",
    "    def guess_function(guess):\n",
    "        assert guess in WORD_FREQ\n",
    "        return guess < secret_word\n",
    "    return guess_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search Idea\n",
    "\n",
    "The first idea is to ignore the frequencies and binary search on the correct word. In the cell below, `binary_search_game` receives a `guess_function` which was created by a call to `create_game`. Your code should use this `guess_function` to deduce what the secret word was, as well as keep track of how many guesses it took. **In the cell below, write code that returns the deduced secret word and number of guesses required**.  \n",
    "\n",
    "*Hint: If you want help implementing binary search, you could model it off of `binary_search_word_generation`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def binary_search_game(guess_function):\n",
    "    \"\"\"Use binary search to guess the secret word.\"\"\"\n",
    "    guesses = 0\n",
    "    deduced_word = None\n",
    "    # BEGIN SOLUTION\n",
    "    i, j = 0, len(sorted_words) - 1\n",
    "    while i < j:\n",
    "        mid = (i + j) // 2\n",
    "        word_to_guess = sorted_words[mid]\n",
    "        if guess_function(word_to_guess):\n",
    "            i = mid + 1\n",
    "        else:\n",
    "            j = mid\n",
    "        guesses += 1\n",
    "    deduced_word = sorted_words[i]\n",
    "    # END SOLUTION\n",
    "    return deduced_word, guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"binary_search_game\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following function to test your code. **While your implementation may not get the exact same number of guesses, it should take 9 or 10 guesses**. **It should also be deducing the correct word**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_binary_search_game():\n",
    "    '''Sanity checks for binary_search_game.\n",
    "    \n",
    "    While your implementation may give different numbers, the number of guesses\n",
    "    should be 9 or 10.\n",
    "    '''\n",
    "    words = ['find', 'time', 'great', 'anyone', 'lying']\n",
    "    print([binary_search_game(create_game(w)) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staff solution gets [('find', 10), ('time', 10), ('great', 10), ('anyone', 10), ('lying', 9)].\n",
    "test_binary_search_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huffman Coding Idea\n",
    "\n",
    "The second idea uses the frequencies and is similar to [Huffman Coding](https://en.wikipedia.org/wiki/Huffman_coding).\n",
    "\n",
    "It works as follows:\n",
    "\n",
    "1. Sort all the words in alphabetical order in a list.\n",
    "2. Go through all consecutive pairs of words. For each pair, consider the sum of the two frequencies. Find the pair whose sum is minimal.\n",
    "3. Combine those two words into a node, and make the frequency their sum. The node's left child will be the first word in the pair and the node's right child will be the second word in the pair.\n",
    "4. Replace the two words with the node in the list.\n",
    "5. Go back to step 1, and now treating nodes and words as the same, repeat until there's only one node left.\n",
    "6. This node is the root of the Huffman Tree.\n",
    "\n",
    "When creating new nodes, we also need to set `rightmost_word`. It'll be useful when we try to guess the secret word, which works as follows.\n",
    "\n",
    "1. Set the current node to the root.\n",
    "2. Guess the `rightmost_word` of the current node's left child.\n",
    "3. If this is before the secret word, than the secret word must be in the right child. Otherwise, it's in the left child.\n",
    "4. Go back to step 2. Repeat until we've reached a leaf in this tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanNode:\n",
    "    def __init__(self, freq, word=None):\n",
    "        # The total frequency of the words in our own subtree.\n",
    "        self.freq = freq\n",
    "        # Only non-null in leaf nodes.\n",
    "        self.word = word\n",
    "        # The rightmost word in our own subtree.\n",
    "        self.rightmost_word = word\n",
    "        # Our children nodes\n",
    "        self.left_subtree = None\n",
    "        self.right_subtree = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following cell, fill code to generate the HuffmanTree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def build_huffman_tree():\n",
    "    sorted_words = sorted(list(WORD_FREQ))\n",
    "    nodes = [HuffmanNode(WORD_FREQ[w], w) for w in sorted_words]\n",
    "    # Will need to combine two nodes len(WORD_FREQ) - 1 times.\n",
    "    for i in range(len(WORD_FREQ) - 1):\n",
    "        min_node_idx = None\n",
    "        min_freq = None\n",
    "        # Choose the consecutive pair of nodes with smallest frequency sum to\n",
    "        # combine.\n",
    "        for j in range(0, len(nodes) - 1):\n",
    "            freq = nodes[j].freq + nodes[j+1].freq\n",
    "            if min_freq is None or freq < min_freq:\n",
    "                min_node_idx = j\n",
    "                min_freq = freq\n",
    "        new_node = HuffmanNode(min_freq)\n",
    "        # Setup the new node and then replace the current two nodes in the list\n",
    "        # with the new node.\n",
    "        \n",
    "        # TODO: Implement the rest of the function\n",
    "        # BEGIN SOLUTION\n",
    "        new_node.left_subtree = nodes[min_node_idx]\n",
    "        new_node.right_subtree = nodes[min_node_idx + 1]\n",
    "        new_node.rightmost_word = new_node.right_subtree.rightmost_word\n",
    "        nodes.pop(min_node_idx)\n",
    "        nodes.pop(min_node_idx)\n",
    "        nodes.insert(min_node_idx, new_node)\n",
    "        # END SOLUTION\n",
    "    return nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"build_huffman_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the cell below, write code that plays a game with the HuffmanTree and returns the deduced word and number of guesses.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "root = build_huffman_tree()\n",
    "\n",
    "def huffman_game(guess_function):\n",
    "    \"\"\"Use the Huffman Tree to guess the secret word.\"\"\"\n",
    "    guesses = 0\n",
    "    deduced_word = None\n",
    "    # BEGIN SOLUTION\n",
    "    curr_node = root\n",
    "    while curr_node.left_subtree:\n",
    "        if guess_function(curr_node.left_subtree.rightmost_word):\n",
    "            curr_node = curr_node.right_subtree\n",
    "        else:\n",
    "            curr_node = curr_node.left_subtree\n",
    "        guesses += 1\n",
    "    deduced_word = curr_node.word\n",
    "    # END SOLUTION\n",
    "    return deduced_word, guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"huffman_game\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following function to test your code. **While your implementation may not get the exact same number of guesses, it should be deducing the correct word**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_huffman_game():\n",
    "    '''Sanity checks for huffman_game.\n",
    "    \n",
    "    The number of guesses may not be less than binary search for particular\n",
    "    examples.\n",
    "    '''\n",
    "    words = ['find', 'time', 'great', 'anyone', 'lying']\n",
    "    print([huffman_game(create_game(w)) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staff solution gets [('find', 8), ('time', 6), ('great', 8), ('anyone', 8), ('lying', 10)].\n",
    "test_huffman_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "In this section, we'll try to compare the average number of guesses required by each of the two methods and connect it to entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following cell, compute the entropy of the distribution for the secret word.**\n",
    "\n",
    "*Note: By default, np.log uses the natural log.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "entropy = None\n",
    "\"\"\"Fill out the rest of the code to calculate the entropy of the distribution for the secret word.\"\"\"\n",
    "# BEGIN SOLUTION\n",
    "probs = sorted_word_freqs / total_freq\n",
    "entropy = np.sum(- probs * np.log2(probs))\n",
    "# END SOLUTION\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use sampling to estimate the mean number of guesses for each method. In particular, if $X_i$ is the number of guesses required for trial $i$, we can approximate\n",
    "$$\n",
    "E[X] \\approx \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 100000\n",
    "binary_search = np.zeros(SAMPLES)\n",
    "huffman = np.zeros(SAMPLES)\n",
    "for i in range(SAMPLES):\n",
    "    secret_word = generate_secret_word()\n",
    "    _, binary_search[i] = binary_search_game(create_game(secret_word))\n",
    "    _, huffman[i] = huffman_game(create_game(secret_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(4, 15)\n",
    "plt.hist(binary_search, bins, alpha=0.5, label='Binary Search')\n",
    "plt.hist(huffman, bins, alpha=0.5, label='Huffman')\n",
    "plt.xlabel('Number of Guesses')\n",
    "plt.legend()\n",
    "plt.title('Guess My Word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create confidence intervals for $E[X]$. We know that $\\frac{1}{n} \\sum_{i=1}^n X_i \\sim \\mathcal{N}(E[X], \\frac{var(X)}{n})$ by the CLT. **In the following cell, calculate `sigma_n` and `mu`**. We can use the sample mean to estimate $E[X]$ and sample variance to estimate $var(X)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "tags": [
     "otter_assign_solution_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def confidence_interval_95(samples):\n",
    "    mu, sigma_n = 0, 0\n",
    "    # BEGIN SOLUTION\n",
    "    sigma_n = np.std(samples) / np.sqrt(len(samples))\n",
    "    mu = np.mean(samples)\n",
    "    # END SOLUTION\n",
    "    return f'{mu:.3f} +- {1.96 * sigma_n:.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"confidence_interval_95\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Binary Search: {confidence_interval_95(binary_search)}')\n",
    "print(f'Huffman: {confidence_interval_95(huffman)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "We recommend you to direct submit the .ipynb file after you finish the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "binary_search_game": {
     "name": "binary_search_game",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_binary_search_game_public():\n...     \"\"\"tests for binary_search_game.\"\"\"\n...     test_word = 'test'\n...     (deduced, guesses) = binary_search_game(create_game(test_word))\n...     assert deduced == test_word, f'Expected {test_word} but got {deduced}'\n...     assert isinstance(guesses, int), f'Expected guesses to be int but got {type(guesses)}'\n...     assert guesses > 0, f'Expected positive number of guesses but got {guesses}'\n...     assert guesses <= 12, f'Used more guesses than words'\n...     for word in ['find', 'time', 'great', 'anyone', 'lying']:\n...         (deduced, guesses) = binary_search_game(create_game(word))\n...         assert deduced == word, f'Expected {word} but got {deduced}'\n...         assert isinstance(guesses, int)\n...         assert guesses > 0\n...         assert guesses <= 12\n>>> test_binary_search_game_public()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "build_huffman_tree": {
     "name": "build_huffman_tree",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def collect_words(node, words):\n...     if node.word:\n...         words.add(node.word)\n...     if node.left_subtree:\n...         collect_words(node.left_subtree, words)\n...     if node.right_subtree:\n...         collect_words(node.right_subtree, words)\n>>> \n>>> def test_all_words(root):\n...     assert root.freq == sum(WORD_FREQ.values()), f'Expected {sum(WORD_FREQ.values())} but got {root.freq}'\n...     words = set()\n...     collect_words(root, words)\n...     assert words == set(WORD_FREQ.keys()), f'Expected {set(WORD_FREQ.keys())} but got {words}'\n>>> root = build_huffman_tree()\n>>> test_all_words(root)\n>>> \n>>> def check_rightmost(node):\n...     if not node.right_subtree:\n...         assert node.rightmost_word == node.word, f'Expected {node.word} but got {node.rightmost_word}'\n...         return\n...     assert node.rightmost_word == node.right_subtree.rightmost_word\n...     check_rightmost(node.left_subtree)\n...     check_rightmost(node.right_subtree)\n>>> root = build_huffman_tree()\n>>> check_rightmost(root)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "confidence_interval_95": {
     "name": "confidence_interval_95",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert confidence_interval_95([1 for _ in range(20)]) == '1.000 +- 0.000'\n>>> assert confidence_interval_95([0 for _ in range(10)] + [1 for _ in range(10)]) == '0.500 +- 0.219'\n>>> (mean_bin, var_bin) = confidence_interval_95(binary_search).split('+-')\n>>> (mean_huff, var_huff) = confidence_interval_95(huffman).split('+-')\n>>> assert float(mean_bin) > float(mean_huff)\n>>> assert float(var_bin) < 0.01\n>>> assert float(var_huff) > 0.01\n>>> assert float(mean_bin) > 9\n>>> assert float(mean_huff) < 9\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "entropy": {
     "name": "entropy",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert abs(entropy - 7.935746) < 1e-05, 'Entropy is incorrect'\n",
         "hidden": true,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "generate_secret_word": {
     "name": "generate_secret_word",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_generate_secret_word():\n...     for _ in range(1000):\n...         word = generate_secret_word()\n...         assert word in WORD_FREQ, f\"Generated word '{word}' not in word frequency dictionary\"\n...     samples = 100000\n...     counts = {}\n...     for _ in range(samples):\n...         word = generate_secret_word()\n...         counts[word] = counts.get(word, 0) + 1\n...     top_words = sorted(WORD_FREQ.items(), key=lambda x: x[1], reverse=True)[:10]\n...     for (word, _) in top_words:\n...         expected_freq = WORD_FREQ[word] / total_freq\n...         actual_freq = counts.get(word, 0) / samples\n...         assert abs(expected_freq - actual_freq) < 0.005, f\"Word '{word}' frequency {actual_freq:.3f} differs too much from expected {expected_freq:.3f}\"\n>>> test_generate_secret_word()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "huffman_game": {
     "name": "huffman_game",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_huffman_game_public():\n...     \"\"\"tests for huffman_game.\"\"\"\n...     test_word = 'test'\n...     (deduced, guesses) = huffman_game(create_game(test_word))\n...     assert deduced == test_word, f'Expected {test_word} but got {deduced}'\n...     assert isinstance(guesses, int), f'Expected guesses to be int but got {type(guesses)}'\n...     assert guesses > 0, f'Expected positive number of guesses but got {guesses}'\n...     assert guesses <= 15, f'Used more guesses than words'\n...     for word in ['find', 'time', 'great', 'anyone', 'lying']:\n...         (deduced, guesses) = huffman_game(create_game(word))\n...         assert deduced == word, f'Expected {word} but got {deduced}'\n...         assert isinstance(guesses, int)\n...         assert guesses > 0\n...         assert guesses <= 11\n>>> test_huffman_game_public()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
